{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dimbul/Desktop/personal/deep-learning/llm-training/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from model import Inference, GPTConfig, GPTModel, Tokenizor, InternalWeights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying the data\n"
     ]
    }
   ],
   "source": [
    "#GPT2 Model im Implementation \n",
    "gpt_conf = GPTConfig()\n",
    "gpt_model, hf_weights = GPTModel(gpt_conf).load_pretrained_weights()\n",
    "gpt_state = gpt_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"Hello, I'm a language model,\"\n",
    "#input = [\"Hello, I'm a language model,\"]\n",
    "t = Tokenizor()\n",
    "inf = Inference(model=gpt_model, tokenizor=t)\n",
    "tokens = t.tokenize(input=input, B=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size 1\n",
      "Current Token lenght 8\n",
      "> Hello, I'm a language model, not a designer. That's all.\"\n",
      "\n",
      "Advertisement\n",
      "\n",
      "\"You're in a lot of trouble,\"\n"
     ]
    }
   ],
   "source": [
    "inf.sample(idx=tokens, seq_len=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iw = InternalWeights(model=gpt_model, tokenizor=t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size 1\n",
      "Current Token lenght 8\n"
     ]
    }
   ],
   "source": [
    "atten_weights = iw.get_atten(idx = tokens, seq_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(atten_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = atten_weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 8, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [6.7076e-03, 9.9329e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [7.5624e-03, 8.4049e-03, 9.8403e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [1.4310e-03, 2.6437e-03, 4.4032e-03, 9.9152e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [1.7698e-03, 4.8090e-03, 4.1432e-03, 3.2679e-04, 9.8895e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [1.3257e-02, 1.4160e-03, 1.2549e-02, 1.0162e-02, 1.6027e-03, 9.6101e-01,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [4.5448e-04, 4.6352e-04, 1.0316e-03, 8.2328e-04, 5.8749e-05, 3.9128e-04,\n",
       "         9.9678e-01, 0.0000e+00],\n",
       "        [1.2156e-03, 4.8873e-01, 2.0043e-03, 3.2256e-04, 2.6163e-04, 1.3634e-05,\n",
       "         3.6227e-05, 5.0741e-01]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = 0\n",
    "layer1[0][1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,    11,   314,  1101,   257,  3303,  2746,    11]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello, I'm a language model,\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
